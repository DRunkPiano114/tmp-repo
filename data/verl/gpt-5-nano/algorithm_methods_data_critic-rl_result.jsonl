{"function_name": "RewardModelForCritic.build_revision_messages", "overview": "Builds prompt messages for generating revised code. Combines original problem, initial solution, and critique into chat template format.", "function_signature": "def build_revision_messages(self, init_messages, critique):", "input_parameters": "- `init_messages`: Initial dialogue history list containing problem (user role) and initial solution (assistant role)\n- `critique`: Model-generated critique text string", "detailed_description": "Function receives initial dialogue history and critique text, validates that initial dialogue history is list type and last message role is assistant, calls related functions for content cleaning (keeping only code portion) and updating, then converts processed plain text critique with no leading/trailing whitespace and revision instruction \"Please finalize your answer accordingly using the same format.\" into new message with user role appended to end of dialogue.", "output": "- Complete dialogue message list (List[Dict]) containing original problem, cleaned initial code, and revision instruction", "func_implementation": "", "test_code_path": "code/test_code/test_build_revision_messages.py", "implementation_location": "code/ctrl/rl/critic_rm.py:line 136-150", "prompt": [{"role": "system", "content": "You are a Python programmer developing with the verl framework. verl (Volcano Engine Reinforcement Learning) is a flexible, efficient and production-ready RL training library for large language models (LLMs). It supports various RL algorithms like PPO and GRPO, integrates with mainstream frameworks including FSDP, Megatron-LM, vLLM, and SGLang, features state-of-the-art throughput performance and flexible device mapping capabilities, and scales to hundreds of GPUs and hundreds of billion parameter models."}, {"role": "user", "content": "Please implement a function named `RewardModelForCritic.build_revision_messages`.\n\n**Function Overview:**\nBuilds prompt messages for generating revised code. Combines original problem, initial solution, and critique into chat template format.\n\n**Function Signature:**\n```python\ndef build_revision_messages(self, init_messages, critique):\n```\n\n**Input Parameters:**\n- `init_messages`: Initial dialogue history list containing problem (user role) and initial solution (assistant role)\n- `critique`: Model-generated critique text string\n\n**Detailed Description:**\nFunction receives initial dialogue history and critique text, validates that initial dialogue history is list type and last message role is assistant, calls related functions for content cleaning (keeping only code portion) and updating, then converts processed plain text critique with no leading/trailing whitespace and revision instruction \"Please finalize your answer accordingly using the same format.\" into new message with user role appended to end of dialogue.\n\n**Expected Output:**\n- Complete dialogue message list (List[Dict]) containing original problem, cleaned initial code, and revision instruction\n\nPlease implement this function based on the above information, ensuring that:\n1. The function signature matches the one provided above\n2. The implementation follows the logic described in the detailed description\n3. All input parameters are properly handled\n4. The return value matches the expected output format\n5. The code style is clear with necessary comments\n\nPlease provide the Python function implementation code directly."}], "completions": ["def build_revision_messages(self, init_messages, critique):\n    \"\"\"\n    Build a revision prompt sequence for code revision.\n\n    This method validates the input dialogue, extracts the code portion from the\n    initial assistant solution, and appends a revision instruction as a new\n    user message containing the cleaned critique.\n\n    Expected output: [problem_message, cleaned_code_message, revision_request_message]\n    \"\"\"\n    import re\n\n    # Basic validation of input\n    if not isinstance(init_messages, list):\n        raise TypeError(\"init_messages must be a list of message dictionaries.\")\n    if len(init_messages) < 2:\n        raise ValueError(\"init_messages must contain at least a problem message and an initial solution.\")\n    \n    problem_message = init_messages[0]\n    last_message = init_messages[-1]\n\n    if not isinstance(problem_message, dict) or \"role\" not in problem_message or \"content\" not in problem_message:\n        raise ValueError(\"The problem message must be a dict with 'role' and 'content' keys.\")\n    if not isinstance(last_message, dict) or \"role\" not in last_message or \"content\" not in last_message:\n        raise ValueError(\"The initial solution message must be a dict with 'role' and 'content' keys.\")\n    if str(last_message.get(\"role\", \"\")).lower() != \"assistant\":\n        raise ValueError(\"The last message in init_messages must be from the assistant.\")\n\n    problem_content = problem_message.get(\"content\", \"\")\n    initial_solution_content = last_message.get(\"content\", \"\")\n\n    # Helper: extract code portion from text\n    def _extract_code(text: str) -> str:\n        if not text:\n            return \"\"\n        # 1) Try fenced code blocks with triple backticks\n        blocks = re.findall(r\"```(?:\\w+)?\\n([\\s\\S]*?)\\n```\", text)\n        if blocks:\n            return \"\\n\\n\".join(blocks).strip()\n        # 2) Try inline code blocks surrounded by single backticks\n        inline_blocks = re.findall(r\"`([^`]+)`\", text)\n        if inline_blocks:\n            return \"\\n\".join(inline_blocks).strip()\n        # 3) Indented code blocks (4 spaces or a tab)\n        lines = text.splitlines()\n        code_lines = []\n        in_code_block = False\n        for line in lines:\n            if line.startswith(\"    \") or line.startswith(\"\\t\"):\n                code_lines.append(line.rstrip(\"\\n\"))\n                in_code_block = True\n            else:\n                if in_code_block:\n                    code_lines.append(line.rstrip(\"\\n\"))\n        if code_lines:\n            return \"\\n\".join(code_lines).strip()\n        # 4) Fallback: pick lines that look like code (basic heuristics)\n        candidate_lines = []\n        for line in lines:\n            if any(kw in line for kw in (\"def \", \"class \", \"import \", \"from \", \"return \", \"for \", \"while \", \"if \", \"else:\", \"elif \", \"=\")):\n                candidate_lines.append(line)\n        if candidate_lines:\n            return \"\\n\".join(candidate_lines).strip()\n        # If nothing identified, return original text trimmed\n        return text.strip()\n\n    # Clean/keep only the code portion from the initial solution\n    cleaned_code = _extract_code(initial_solution_content)\n\n    # Build the new revision instruction message\n    critique_clean = (critique or \"\").strip()\n    revision_instruction = \"Please finalize your answer accordingly using the same format.\"\n    revision_content = f\"{critique_clean} {revision_instruction}\".strip()\n\n    revision_message = {\n        \"role\": \"user\",\n        \"content\": revision_content\n    }\n\n    # Assemble final dialogue: [problem, cleaned initial code, revision request]\n    cleaned_lines_message = {\n        \"role\": \"assistant\",\n        \"content\": cleaned_code\n    }\n\n    return [problem_content and problem_message or {\"role\": \"user\", \"content\": \"\"},\n            cleaned_lines_message,\n            revision_message]"], "usage": {"prompt_tokens": 398, "completion_tokens": 3705, "total_tokens": 4103, "per_completion": [{"prompt_tokens": 398, "completion_tokens": 3705, "total_tokens": 4103}]}, "results": [false], "pass_ratios": [0.0]}
{"function_name": "RewardModelForCritic.get_reward_all", "overview": "Concurrently executes sandbox tests for multiple critique-revision pairs, computing verifiable rewards. Improves execution efficiency through asynchronous I/O mechanism, supporting large-scale parallel evaluation.", "function_signature": "async def get_reward_all(\nself, critiques: List[str], revisions: List[str], samples: List[Any]\n) -> List[float]:", "input_parameters": "- `critiques`: Critique text list, each element corresponding to a generated critique\n- `revisions`: Revised code list, one-to-one correspondence with critiques\n- `samples`: Test sample list containing test cases and problem metadata", "detailed_description": "Function calls underlying reward computation method for each triplet (sample, critique, revision), evaluating improvement quality of revised version relative to original sample, returning numerical reward scores. All computation tasks execute asynchronously and concurrently, maximizing processing throughput while ensuring resource control, with default maximum concurrency set to MAX_REQUESTS (256), requiring progress bar (\"Generating rewards\") for real-time completion feedback.", "output": "- Float list, each element representing reward value for corresponding critique-revision pair, range [0.0, 1.0]", "func_implementation": "", "test_code_path": "code/test_code/test_get_reward_all.py", "implementation_location": "code/ctrl/rl/critic_rm.py:line 198-209", "prompt": [{"role": "system", "content": "You are a Python programmer developing with the verl framework. verl (Volcano Engine Reinforcement Learning) is a flexible, efficient and production-ready RL training library for large language models (LLMs). It supports various RL algorithms like PPO and GRPO, integrates with mainstream frameworks including FSDP, Megatron-LM, vLLM, and SGLang, features state-of-the-art throughput performance and flexible device mapping capabilities, and scales to hundreds of GPUs and hundreds of billion parameter models."}, {"role": "user", "content": "Please implement a function named `RewardModelForCritic.get_reward_all`.\n\n**Function Overview:**\nConcurrently executes sandbox tests for multiple critique-revision pairs, computing verifiable rewards. Improves execution efficiency through asynchronous I/O mechanism, supporting large-scale parallel evaluation.\n\n**Function Signature:**\n```python\nasync def get_reward_all(\nself, critiques: List[str], revisions: List[str], samples: List[Any]\n) -> List[float]:\n```\n\n**Input Parameters:**\n- `critiques`: Critique text list, each element corresponding to a generated critique\n- `revisions`: Revised code list, one-to-one correspondence with critiques\n- `samples`: Test sample list containing test cases and problem metadata\n\n**Detailed Description:**\nFunction calls underlying reward computation method for each triplet (sample, critique, revision), evaluating improvement quality of revised version relative to original sample, returning numerical reward scores. All computation tasks execute asynchronously and concurrently, maximizing processing throughput while ensuring resource control, with default maximum concurrency set to MAX_REQUESTS (256), requiring progress bar (\"Generating rewards\") for real-time completion feedback.\n\n**Expected Output:**\n- Float list, each element representing reward value for corresponding critique-revision pair, range [0.0, 1.0]\n\nPlease implement this function based on the above information, ensuring that:\n1. The function signature matches the one provided above\n2. The implementation follows the logic described in the detailed description\n3. All input parameters are properly handled\n4. The return value matches the expected output format\n5. The code style is clear with necessary comments\n\nPlease provide the Python function implementation code directly."}], "completions": ["async def get_reward_all(\n    self, critiques: List[str], revisions: List[str], samples: List[Any]\n) -> List[float]:\n    \"\"\"\n    Concurrently compute rewards for each triplet (sample, critique, revision).\n    Uses a bounded level of concurrency to maximize throughput while\n    avoiding resource overuse, with a progress bar to monitor progress.\n\n    Returns:\n        List[float]: rewards in [0.0, 1.0], aligned with the input triplets.\n    \"\"\"\n    import asyncio\n    import warnings\n    from typing import List, Any\n\n    MAX_REQUESTS = 256  # default maximum concurrency\n    # Validate inputs and determine effective processing length\n    if critiques is None or revisions is None or samples is None:\n        return []\n\n    n = min(len(critiques), len(revisions), len(samples))\n    if n == 0:\n        return []\n\n    if not (len(critiques) == len(revisions) == len(samples)):\n        warnings.warn(\n            \"Lengths of critiques, revisions, and samples differ; truncating to the shortest length.\",\n            UserWarning,\n        )\n\n    # Discover an underlying reward computation method on this object\n    reward_method = None\n    candidate_names = (\"get_reward\", \"compute_reward\", \"_get_reward\", \"_compute_reward\", \"reward_for_triplet\")\n    for name in candidate_names:\n        attr = getattr(self, name, None)\n        if callable(attr):\n            reward_method = attr\n            break\n    if reward_method is None:\n        raise RuntimeError(\"No reward computation method found on RewardModelForCritic.\")\n\n    # Semaphore to cap concurrency\n    semaphore = asyncio.Semaphore(MAX_REQUESTS)\n\n    async def _compute_for_index(i: int):\n        sample = samples[i]\n        critique = critiques[i]\n        revision = revisions[i]\n        async with semaphore:\n            result = reward_method(sample, critique, revision)\n            if asyncio.iscoroutine(result):\n                result = await result\n            try:\n                val = float(result)\n            except Exception:\n                val = 0.0\n            # Clamp to [0.0, 1.0]\n            val = max(0.0, min(1.0, val))\n            return i, val\n\n    # Create tasks and a progress bar\n    tasks = [asyncio.create_task(_compute_for_index(i)) for i in range(n)]\n    try:\n        from tqdm import tqdm\n        bar = tqdm(total=n, desc=\"Generating rewards\")\n    except Exception:\n        bar = None\n\n    results = [0.0] * n\n    for fut in asyncio.as_completed(tasks):\n        idx, value = await fut\n        results[idx] = value\n        if bar is not None:\n            bar.update(1)\n\n    if bar is not None:\n        bar.close()\n\n    return results"], "usage": {"prompt_tokens": 443, "completion_tokens": 3983, "total_tokens": 4426, "per_completion": [{"prompt_tokens": 443, "completion_tokens": 3983, "total_tokens": 4426}]}, "results": [false], "pass_ratios": [0.0]}
{"function_name": "sanitize", "overview": "Extracts pure code blocks from mixed text containing code and explanations, removes explanatory text, preserves markdown format code block structure.", "function_signature": "def sanitize(text):", "input_parameters": "- `text`: Mixed text string containing code blocks", "detailed_description": "Function uses regular expressions to identify and extract markdown format code blocks, matching code blocks wrapped in triple backticks through regex, recognizing cases with or without python identifier. Matching process is case-insensitive. After successful match, extracts content of first code block and reformats it to standard markdown format ````python\\n{code}\\n``` for return. If no code block found in text or code block is empty, directly returns original text.", "output": "- Formatted code block string (````python\\n{code}\\n```) or original text (when no code block)\nIn `build_revision_messages` function, used to clean model-generated initial solution, remove explanatory text, keep only code portion, ensuring conciseness of revision prompt.", "func_implementation": "", "test_code_path": "code/test_code/test_sanitize_desanitize.py", "implementation_location": "code/ctrl/rl/critic_rm.py:line 76-84", "prompt": [{"role": "system", "content": "You are a Python programmer developing with the verl framework. verl (Volcano Engine Reinforcement Learning) is a flexible, efficient and production-ready RL training library for large language models (LLMs). It supports various RL algorithms like PPO and GRPO, integrates with mainstream frameworks including FSDP, Megatron-LM, vLLM, and SGLang, features state-of-the-art throughput performance and flexible device mapping capabilities, and scales to hundreds of GPUs and hundreds of billion parameter models."}, {"role": "user", "content": "Please implement a function named `sanitize`.\n\n**Function Overview:**\nExtracts pure code blocks from mixed text containing code and explanations, removes explanatory text, preserves markdown format code block structure.\n\n**Function Signature:**\n```python\ndef sanitize(text):\n```\n\n**Input Parameters:**\n- `text`: Mixed text string containing code blocks\n\n**Detailed Description:**\nFunction uses regular expressions to identify and extract markdown format code blocks, matching code blocks wrapped in triple backticks through regex, recognizing cases with or without python identifier. Matching process is case-insensitive. After successful match, extracts content of first code block and reformats it to standard markdown format ````python\\n{code}\\n``` for return. If no code block found in text or code block is empty, directly returns original text.\n\n**Expected Output:**\n- Formatted code block string (````python\\n{code}\\n```) or original text (when no code block)\nIn `build_revision_messages` function, used to clean model-generated initial solution, remove explanatory text, keep only code portion, ensuring conciseness of revision prompt.\n\nPlease implement this function based on the above information, ensuring that:\n1. The function signature matches the one provided above\n2. The implementation follows the logic described in the detailed description\n3. All input parameters are properly handled\n4. The return value matches the expected output format\n5. The code style is clear with necessary comments\n\nPlease provide the Python function implementation code directly."}], "completions": ["def sanitize(text):\n    \"\"\"\n    Extracts the first Markdown-style code block from the input text and returns it\n    in a standardized Python code block format.\n\n    - Looks for code blocks wrapped with triple backticks, optionally prefixed with\n      a Python language tag (e.g., ```python or ```py).\n    - Captures the first such code block content.\n    - Returns the content wrapped as:\n      ```python\n      <code>\n      ```\n    - If no code block is found or the extracted code is empty, returns the original text.\n\n    Parameters:\n    - text (str): Mixed text containing code blocks and explanations.\n\n    Returns:\n    - str: Reformatted code block or the original text if no suitable code block is found.\n    \"\"\"\n    import re\n\n    if not isinstance(text, str):\n        return text\n\n    # Pattern to capture first code block with optional language spec (python/py)\n    # The pattern is case-insensitive and uses DOTALL to allow newlines inside code.\n    pattern = re.compile(r'```(?:python|py)?\\s*\\n([\\s\\S]*?)\\n```', re.IGNORECASE)\n\n    match = pattern.search(text)\n    if not match:\n        # No code block found; return original text\n        return text\n\n    code = match.group(1).strip()\n    if not code:\n        # Empty code block; return original text\n        return text\n\n    # Return standardized Markdown code block in Python\n    return f\"```python\\n{code}\\n```\""], "usage": {"prompt_tokens": 409, "completion_tokens": 1558, "total_tokens": 1967, "per_completion": [{"prompt_tokens": 409, "completion_tokens": 1558, "total_tokens": 1967}]}, "results": [false], "pass_ratios": [0.0]}
{"function_name": "desanitize", "overview": "Removes markdown code block markers (triple backticks) from code text, extracts pure code string.", "function_signature": "def desanitize(text):", "input_parameters": "- `text`: Text with or without markdown code block markers", "detailed_description": "Function uses regular expression to match code blocks wrapped in triple backticks, recognizing cases with or without python identifier. After successful match, extracts content inside code block, returns after removing leading/trailing whitespace. If no code block format found in text, directly returns original text.", "output": "- Pure code string with markdown markers removed\nIn `get_sandbox_response` function, used to extract pure code from revision text, remove markdown format markers, prepare code for sandbox execution.", "func_implementation": "", "test_code_path": "code/test_code/test_sanitize_desanitize.py", "implementation_location": "code/ctrl/rl/critic_rm.py:line 66-73", "prompt": [{"role": "system", "content": "You are a Python programmer developing with the verl framework. verl (Volcano Engine Reinforcement Learning) is a flexible, efficient and production-ready RL training library for large language models (LLMs). It supports various RL algorithms like PPO and GRPO, integrates with mainstream frameworks including FSDP, Megatron-LM, vLLM, and SGLang, features state-of-the-art throughput performance and flexible device mapping capabilities, and scales to hundreds of GPUs and hundreds of billion parameter models."}, {"role": "user", "content": "Please implement a function named `desanitize`.\n\n**Function Overview:**\nRemoves markdown code block markers (triple backticks) from code text, extracts pure code string.\n\n**Function Signature:**\n```python\ndef desanitize(text):\n```\n\n**Input Parameters:**\n- `text`: Text with or without markdown code block markers\n\n**Detailed Description:**\nFunction uses regular expression to match code blocks wrapped in triple backticks, recognizing cases with or without python identifier. After successful match, extracts content inside code block, returns after removing leading/trailing whitespace. If no code block format found in text, directly returns original text.\n\n**Expected Output:**\n- Pure code string with markdown markers removed\nIn `get_sandbox_response` function, used to extract pure code from revision text, remove markdown format markers, prepare code for sandbox execution.\n\nPlease implement this function based on the above information, ensuring that:\n1. The function signature matches the one provided above\n2. The implementation follows the logic described in the detailed description\n3. All input parameters are properly handled\n4. The return value matches the expected output format\n5. The code style is clear with necessary comments\n\nPlease provide the Python function implementation code directly."}], "completions": ["import re\n\ndef desanitize(text):\n    \"\"\"\n    Remove markdown code block markers from text.\n    If a code block is detected (``` or ```<lang> ... ```), return the inner code\n    content with leading/trailing whitespace removed. If no code block is found,\n    return the original text.\n    \"\"\"\n    if not isinstance(text, str):\n        text = str(text)\n\n    # Match code blocks of the form:\n    # ``` or ```python  ...  ```\n    pattern = r\"```(?:[a-zA-Z0-9_\\-+]+)?\\n([\\s\\S]*?)```\"\n    match = re.search(pattern, text)\n    if match:\n        code = match.group(1)\n        return code.strip()\n\n    return text"], "usage": {"prompt_tokens": 356, "completion_tokens": 1056, "total_tokens": 1412, "per_completion": [{"prompt_tokens": 356, "completion_tokens": 1056, "total_tokens": 1412}]}, "results": [false], "pass_ratios": [0.0]}
{"function_name": "normalize_code", "overview": "Normalizes Python code through Abstract Syntax Tree (AST) level transformation, unifies variable naming, improves cache hit rate.", "function_signature": "def normalize_code(code_str):", "input_parameters": "- `code_str`: Python code string to be normalized", "detailed_description": "Function uniformly renames variables in Python code to standard form (v_0, v_1, ...) through AST parsing, enabling functionally identical but differently named code to be recognized as equivalent. If code has syntax errors, function returns original code without transformation.", "output": "- Normalized code string, or original code (when parsing fails)\nDuring training, model may generate multiple semantically identical but differently named code versions. For example, `x = 1; return x` and `y = 1; return y` are functionally completely equivalent. Through normalization, both are converted to `v_0 = 1; return v_0`, using same cache key, avoiding repeated sandbox execution, significantly improving training efficiency.", "func_implementation": "", "test_code_path": "code/test_code/test_normalize_code.py", "implementation_location": "code/ctrl/rl/critic_rm.py:line 35-63", "prompt": [{"role": "system", "content": "You are a Python programmer developing with the verl framework. verl (Volcano Engine Reinforcement Learning) is a flexible, efficient and production-ready RL training library for large language models (LLMs). It supports various RL algorithms like PPO and GRPO, integrates with mainstream frameworks including FSDP, Megatron-LM, vLLM, and SGLang, features state-of-the-art throughput performance and flexible device mapping capabilities, and scales to hundreds of GPUs and hundreds of billion parameter models."}, {"role": "user", "content": "Please implement a function named `normalize_code`.\n\n**Function Overview:**\nNormalizes Python code through Abstract Syntax Tree (AST) level transformation, unifies variable naming, improves cache hit rate.\n\n**Function Signature:**\n```python\ndef normalize_code(code_str):\n```\n\n**Input Parameters:**\n- `code_str`: Python code string to be normalized\n\n**Detailed Description:**\nFunction uniformly renames variables in Python code to standard form (v_0, v_1, ...) through AST parsing, enabling functionally identical but differently named code to be recognized as equivalent. If code has syntax errors, function returns original code without transformation.\n\n**Expected Output:**\n- Normalized code string, or original code (when parsing fails)\nDuring training, model may generate multiple semantically identical but differently named code versions. For example, `x = 1; return x` and `y = 1; return y` are functionally completely equivalent. Through normalization, both are converted to `v_0 = 1; return v_0`, using same cache key, avoiding repeated sandbox execution, significantly improving training efficiency.\n\nPlease implement this function based on the above information, ensuring that:\n1. The function signature matches the one provided above\n2. The implementation follows the logic described in the detailed description\n3. All input parameters are properly handled\n4. The return value matches the expected output format\n5. The code style is clear with necessary comments\n\nPlease provide the Python function implementation code directly."}], "completions": ["```python\ndef normalize_code(code_str):\n    \"\"\"\n    Normalize Python code by renaming local variables and function arguments\n    to a canonical form (v_0, v_1, ...). The transformation is done via\n    AST-based traversal. If the input code has syntax errors, the original\n    code string is returned.\n\n    Approach (conservative and safe):\n    - Only renames identifiers that are local to a function scope (arguments\n      and local assignments). This avoids breaking imports, built-ins, or\n      module-level names.\n    - Each function gets its own v_0, v_1, ... sequence starting at 0.\n    - Function names themselves are not renamed to preserve recursive references\n      and external calls.\n    - Global module-level names (imports, top-level assignments, etc.) are\n      treated as reserved and won't be renamed.\n    - Uses a small global-collection pass to identify module-level names to avoid\n      renaming them inside function scopes.\n\n    Parameters:\n    - code_str: str, Python source code to normalize\n\n    Returns:\n    - A string with the normalized code if parsing succeeds, otherwise the original code_str.\n    \"\"\"\n    import ast\n\n    if not isinstance(code_str, str):\n        return code_str\n\n    try:\n        tree = ast.parse(code_str)\n    except SyntaxError:\n        # If code can't be parsed, return as-is per specification\n        return code_str\n\n    # 1) Collect module-level (global) names to avoid renaming them inside functions\n    class ModuleGlobalsCollector(ast.NodeVisitor):\n        def __init__(self):\n            self.names = set()\n\n        def visit_FunctionDef(self, node):\n            self.names.add(node.name)\n            self.generic_visit(node)\n\n        def visit_AsyncFunctionDef(self, node):\n            self.names.add(node.name)\n            self.generic_visit(node)\n\n        def visit_ClassDef(self, node):\n            self.names.add(node.name)\n            self.generic_visit(node)\n\n        def visit_Import(self, node):\n            for alias in node.names:\n                if alias.asname:\n                    self.names.add(alias.asname)\n                else:\n                    self.names.add(alias.name.split('.')[0])\n\n        def visit_ImportFrom(self, node):\n            for alias in node.names:\n                if alias.asname:\n                    self.names.add(alias.asname)\n                else:\n                    self.names.add(alias.name)\n\n        def visit_Assign(self, node):\n            for t in node.targets:\n                for n in ast.walk(t):\n                    if isinstance(n, ast.Name):\n                        if isinstance(n.ctx, ast.Store) or isinstance(n.ctx, ast.Load):\n                            self.names.add(n.id)\n            self.generic_visit(node)\n\n        def visit_For(self, node):\n            # loop variable at module scope\n            for t in [node.target]:\n                for n in ast.walk(t):\n                    if isinstance(n, ast.Name):\n                        if isinstance(n.ctx, ast.Store):\n                            self.names.add(n.id)\n            self.generic_visit(node)\n\n    collector = ModuleGlobalsCollector()\n    collector.visit(tree)\n    module_globals = collector.names\n\n    # 2) Transformer to rename local variables and function arguments\n    class VarNormalizer(ast.NodeTransformer):\n        def __init__(self, module_globals):\n            self.module_globals = module_globals\n            self.builtins_names = set(dir(__builtins__)) if hasattr(__builtins__, \"__dict__\") else set(dir(__builtins__))\n            self.scopes = []        # stack of per-scope maps: original_name -> new_name\n            self.next_indices = []    # parallel stack of next v_<i> index per scope\n\n        # Scope helpers\n        def enter_scope(self):\n            self.scopes.append({})\n            self.next_indices.append(0)\n\n        def exit_scope(self):\n            if self.scopes:\n                self.scopes.pop()\n            if self.next_indices:\n                self.next_indices.pop()\n\n        def current_mapping(self):\n            if not self.scopes:\n                return None\n            return self.scopes[-1]\n\n        def _generate(self):\n            idx = self.next_indices[-1]\n            self.next_indices[-1] = idx + 1\n            return f\"v_{idx}\"\n\n        # Function scope handling: rename args and body\n        def visit_FunctionDef(self, node):\n            # Do not rename the function name itself\n            self.enter_scope()\n            # Rename function arguments (positional, kwonly, vararg, kwarg)\n            self._rename_args(node.args)\n\n            # Transform the function body with the new scope\n            new_body = []\n            for n in node.body:\n                new_body.append(self.visit(n))\n            node.body = new_body\n\n            # Do not rename decorators or returns to avoid side-effects\n            # (Optional: could be added with careful handling)\n\n            self.exit_scope()\n            return node\n\n        def _rename_args(self, args):\n            # positional-only args (Python 3.8+)\n            for a in getattr(args, \"posonlyargs\", []):\n                self._rename_arg(a)\n            # regular args\n            for a in getattr(args, \"args\", []):\n                self._rename_arg(a)\n            # vararg\n            if getattr(args, \"vararg\", None):\n                self._rename_arg(args.vararg)\n            # keyword-only args\n            for a in getattr(args, \"kwonlyargs\", []):\n                self._rename_arg(a)\n            # kwarg\n            if getattr(args, \"kwarg\", None):\n                self._rename_arg(args.kwarg)\n\n        def _rename_arg(self, arg):\n            orig = arg.arg\n            new_name = self._get_or_create_mapping(orig)\n            arg.arg = new_name\n\n        def _get_or_create_mapping(self, orig_name):\n            mapping = self.current_mapping()\n            if mapping is not None and orig_name in mapping:\n                return mapping[orig_name]\n            # Respect module globals and builtins: do not rename\n            if orig_name in self.module_globals or orig_name in self.builtins_names:\n                return orig_name\n            # Create a new mapping for a local name\n            new_name = self._generate()\n            if mapping is not None:\n                mapping[orig_name] = new_name\n            return new_name\n\n        # Name node transformation: apply mapping if present or create new local on assignment\n        def visit_Name(self, node):\n            # Do nothing if no scope is active\n            if not self.scopes:\n                return self.generic_visit(node)\n\n            mapping = self.scopes[-1]\n            if node.id in mapping:\n                return ast.copy_location(ast.Name(id=mapping[node.id], ctx=node.ctx), node)\n\n            if isinstance(node.ctx, ast.Store):\n                # Create a mapping for a new local if it's not a reserved/global name\n                if node.id in self.module_globals or node.id in self.builtins_names:\n                    return node\n                new_name = self._generate()\n                mapping[node.id] = new_name\n                return ast.copy_location(ast.Name(id=new_name, ctx=node.ctx), node)\n\n            # For Load: if it's not a local name, keep as is (avoid renaming globals)\n            if node.id in self.module_globals or node.id in self.builtins_names:\n                return node\n            return node\n\n        def visit_Module(self, node):\n            # Do not alter module-level bindings directly; just walk through\n            return self.generic_visit(node)\n\n    transformer = VarNormalizer(module_globals)\n    new_tree = transformer.visit(tree)\n    ast.fix_missing_locations(new_tree)\n\n    # 3) Unparse back to source code\n    try:\n        normalized_code = ast.unparse(new_tree)\n    except Exception:\n        # Fallback to original on any unparsable transformation\n        return code_str\n\n    return normalized_code\n```"], "usage": {"prompt_tokens": 412, "completion_tokens": 12886, "total_tokens": 13298, "per_completion": [{"prompt_tokens": 412, "completion_tokens": 12886, "total_tokens": 13298}]}, "results": [false], "pass_ratios": [0.0]}
